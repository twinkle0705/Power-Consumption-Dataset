{"cells":[{"metadata":{"id":"6QCORJfKLc7T"},"cell_type":"markdown","source":"# Scraping data from pdfs"},{"metadata":{"id":"9h__MswkXHdq","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"! pip install tabula-py\nimport tabula\nimport os\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"id":"MN79QkvAOphh"},"cell_type":"markdown","source":"# Data File 01\n### Region/State wise electricity usage"},{"metadata":{"id":"kbF34YBqmSDI","trusted":true},"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nlink1 = user_secrets.get_secret(\"link1\")\nlink2 = user_secrets.get_secret(\"link2\")\nlink = user_secrets.get_secret(\"link\")","execution_count":null,"outputs":[]},{"metadata":{"id":"uYUXsLf2btIf","outputId":"25fa6c7b-7e87-4bb4-f2f2-db883d58e114","executionInfo":{"status":"ok","timestamp":1591256023496,"user_tz":-330,"elapsed":61730,"user":{"displayName":"Navin Mundhra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgniN_mTRS-2UfcIm1spNh0X1ccg_lMD19cKy8PTg=s64","userId":"04409829077952489554"}},"trusted":true},"cell_type":"code","source":"## READING FROM PDFS AND CONCATINATING TO MERGE FILES INTO ONE. (USED TWO FILES HERE FOR DEMONSTRATION PURPOSES BUT YOU CAN LOOP THROUGH ALL THE FILES)\nfinaldf = tabula.read_pdf(link1, stream=True, pages=4)[0]\nfor i in range(1, 2):\n    filepath = str(link2)\n    finaldf = pd.concat([tabula.read_pdf(filepath, stream=True, pages=4)[0],finaldf], axis=1)\nfinaldf","execution_count":null,"outputs":[]},{"metadata":{"id":"vozbulKApv3K","outputId":"fb37a4b2-4ea7-4edf-a84e-2b735de0e313","executionInfo":{"status":"ok","timestamp":1591256023498,"user_tz":-330,"elapsed":61451,"user":{"displayName":"Navin Mundhra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgniN_mTRS-2UfcIm1spNh0X1ccg_lMD19cKy8PTg=s64","userId":"04409829077952489554"}},"trusted":true},"cell_type":"code","source":"## DROPPING DUPLICATE COLUMNS\nfinaldf = finaldf.loc[:,~finaldf.columns.duplicated()]\n\n## RENAMING COLUMN TO A PROPER NAME\nfinaldf.rename({'Region States':'States'}, axis=1, inplace=True)\n\n## DROPPING REDUNDANT COLUMNS AND ROWS WHICH DO NOT MAKE SENSE\nfinaldf.drop('Unnamed: 0', axis=1, inplace=True)\nfinaldf.dropna(thresh=2, axis=0, inplace=True)\n\n## RESETTING THE INDEX AS ROWS HAVE BEEN DROPPED\nfinaldf.reset_index(drop=True, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## CREATING A COLUMN OF REGION A STATE BELONGS TO AND CLASSIFYING STATES ACCORDINGLY\nfinaldf.insert(1,'Region','NaN')\nfinaldf['Region'][:9] = 'NR'\nfinaldf['Region'][9:17] = 'WR'\nfinaldf['Region'][17:23] = 'SR'\nfinaldf['Region'][23:29] = 'ER'\nfinaldf['Region'][29:36] = 'NER'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## ADDING LATITUDE AND LONGITUDE OF STATES IN THE DATA\n\nfinaldf.insert(2,'Latitude','NaN')\nfinaldf['Latitude'] = finaldf['States'].map({'Punjab':31.51997398,\n                                  'Delhi':28.6699929,\n                                  'Chandigarh':30.71999697,\n                                  'Haryana':28.45000633,\n                                  'HP':31.10002545,\n                                  'J&K':33.45,\n                                  'Rajasthan':26.44999921,\n                                  'NR UP':27.59998069,\n                                  'Uttarakhand':30.32040895,\n                                  'NFF/Railway':'NR',\n                                  'Gujarat':22.2587,\n                                  'MP':21.30039105,\n                                  'Chhattisgarh':22.09042035,\n                                  'Maharashtra':19.25023195,\n                                  'Goa':15.491997,\n                                  'DD':20.4283,\n                                  'DNH':20.26657819,\n                                  'Essar steel':21.6838,\n                                  'Andhra Pradesh':14.7504291,\n                                  'Telangana':18.1124,\n                                  'Karnataka':12.57038129,\n                                  'Kerala':8.900372741,\n                                  'Tamil Nadu':12.92038576,\n                                  'Pondy':11.93499371,\n                                  'Bihar':25.78541445,\n                                  'Jharkhand':23.80039349,\n                                  'DVC':22.4975,\n                                  'Odisha':19.82042971,\n                                  'West Bengal':22.58039044,\n                                  'Sikkim':27.3333303,\n                                  'Arunachal Pradesh':27.10039878,\n                                  'Assam':26.7499809,\n                                  'Manipur':24.79997072,\n                                  'NER Meghalaya':25.57049217,\n                                  'Mizoram':23.71039899,\n                                  'Nagaland':25.6669979,\n                                  'Tripura':23.83540428\n})\n\nfinaldf.insert(3,'Longitude','NaN')\n\nfinaldf['Longitude'] = finaldf['States'].map({'Punjab':75.98000281,\n                                  'Delhi':77.23000403,\n                                  'Chandigarh':76.78000565,\n                                  'Haryana':77.01999101,\n                                  'HP':77.16659704,\n                                  'J&K':76.24,\n                                  'Rajasthan':74.63998124,\n                                  'NR UP':78.05000565,\n                                  'Uttarakhand':78.05000565,\n                                  \n                                  'Gujarat':71.1924,\n                                  'MP':76.13001949,\n                                  'Chhattisgarh':82.15998734,\n                                  'Maharashtra':73.16017493,\n                                  'Goa':73.81800065,\n                                  'DD':72.8397,\n                                  'DNH':73.0166178,\n                                  'Essar steel':72.0824,\n                                  'Andhra Pradesh':78.57002559,\n                                  'Telangana':79.0193,\n                                  'Karnataka':76.91999711,\n                                  'Kerala':76.56999263,\n                                  'Tamil Nadu':79.15004187,\n                                  'Pondy':79.83000037,\n                                  'Bihar':87.4799727,\n                                  'Jharkhand':86.41998572,\n                                  'DVC':88.3527,\n                                  'Odisha':85.90001746,\n                                  'West Bengal':88.32994665,\n                                  'Sikkim':88.6166475,\n                                  'Arunachal Pradesh':93.61660071,\n                                  'Assam':94.21666744,\n                                  'Manipur':93.95001705,\n                                  'NER Meghalaya':91.8800142,\n                                  'Mizoram':92.72001461,\n                                  'Nagaland':94.11657019,\n                                  'Tripura':91.27999914\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## SETTING STATES AS INDEX\nfinaldf = finaldf.set_index('States')\n\n## FIXING NAMES OF A FEW STATES\nfinaldf.rename({'NR UP': 'UP', 'NER Meghalaya': 'Meghalaya'}, inplace=True)\n\nfinaldf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So clean and pretty already! That was easy. With [Tabula](https://tabula-py.readthedocs.io/en/latest/) and [Pandas](https://pandas.pydata.org/docs/) one can easily get the most out of data in pdfs.\n\n# Data File 02\n## Region wise power demand and supply"},{"metadata":{"id":"3W-mSk1QNak-","outputId":"8f3523b2-24a3-4937-d92b-29520290c782","executionInfo":{"status":"ok","timestamp":1591282265856,"user_tz":-330,"elapsed":8135,"user":{"displayName":"Navin Mundhra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgniN_mTRS-2UfcIm1spNh0X1ccg_lMD19cKy8PTg=s64","userId":"04409829077952489554"}},"trusted":true},"cell_type":"code","source":"## READING DATA IN ANOTHER FILE AT PAGE NUMBER 29. MULTIPLE FILES CAN BE MERGED AS SHOWN ABOVE\ndf = tabula.read_pdf(link, stream=True, pages=29)[0]\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## STARTING THE DATAFRAME FROM THE RIGHT PLACE AND GIVING MEANINGFUL NAMES TO COLUMNS\ndf = df.iloc[5:,]\ndf = df.rename({'Unnamed: 0':'Region',\n           'Unnamed: 1':'State',\n           'Requirement/Availability  in MU/DAY': 'Requirement/day',\n           'Requirement/Availability  in MU': 'Requirement/month',\n           'Peak Demand/Peak Met in MW': 'peak_demand',\n           }, axis=1)\ndf","execution_count":null,"outputs":[]},{"metadata":{"id":"RktHi8Vi0FkA","trusted":true},"cell_type":"code","source":"## DROPPING REDUNDANT COLUMNS\ndf.drop(['Unnamed: 2','Unnamed: 3'], axis=1, inplace=True)\n\n## ADDING LATITUDE AND LONGITUDE OF STATES IN THE DATA\ndf.insert(2,'Latitude','NaN')\ndf['Latitude'] = df['State'].map({'Punjab':31.51997398,\n                                  'Delhi':28.6699929,\n                                  'Chandigarh':30.71999697,\n                                  'Haryana':28.45000633,\n                                  'Himachal Pradesh':31.10002545,\n                                  'J&K':33.45,\n                                  'Rajasthan':26.44999921,\n                                  'Uttar Pradesh':27.59998069,\n                                  'Uttarakhand':30.32040895,\n                                  'NFF/Railway':25.751627,\n                                  'Gujarat':22.2587,\n                                  'Madhya Pradesh':21.30039105,\n                                  'Chhattisgarh':22.09042035,\n                                  'Maharashtra':19.25023195,\n                                  'Goa':15.491997,\n                                  'D&D':20.4283,\n                                  'DNH':20.26657819,\n                                  'ESIL':21.6838,\n                                  'Andhra Pradesh':14.7504291,\n                                  'Telangana':18.1124,\n                                  'Karnataka':12.57038129,\n                                  'Kerala':8.900372741,\n                                  'Tamil Nadu':12.92038576,\n                                  'Pondicherry':11.93499371,\n                                  'Bihar':25.78541445,\n                                  'Jharkhand':23.80039349,\n                                  'DVC':22.4975,\n                                  'Odisha':19.82042971,\n                                  'West Bengal':22.58039044,\n                                  'Sikkim':27.3333303,\n                                  'Arunachal Pradesh':27.10039878,\n                                  'Assam':26.7499809,\n                                  'Manipur':24.79997072,\n                                  'Meghalaya':25.57049217,\n                                  'Mizoram':23.71039899,\n                                  'Nagaland':25.6669979,\n                                  'Tripura':23.83540428\n})\n\ndf.insert(3,'Longitude','NaN')\n\ndf['Longitude'] = df['State'].map({'Punjab':75.98000281,\n                                  'Delhi':77.23000403,\n                                  'Chandigarh':76.78000565,\n                                  'Haryana':77.01999101,\n                                  'Himachal Pradesh':77.16659704,\n                                  'J&K':76.24,\n                                  'Rajasthan':74.63998124,\n                                  'Uttar Pradesh':78.05000565,\n                                  'Uttarakhand':78.05000565,\n                                  'NFF/Railway':93.172874,\n                                  'Gujarat':71.1924,\n                                  'Madhya Pradesh':76.13001949,\n                                  'Chhattisgarh':82.15998734,\n                                  'Maharashtra':73.16017493,\n                                  'Goa':73.81800065,\n                                  'D&D':72.8397,\n                                  'DNH':73.0166178,\n                                  'ESIL':72.0824,\n                                  'Andhra Pradesh':78.57002559,\n                                  'Telangana':79.0193,\n                                  'Karnataka':76.91999711,\n                                  'Kerala':76.56999263,\n                                  'Tamil Nadu':79.15004187,\n                                  'Pondicherry':79.83000037,\n                                  'Bihar':87.4799727,\n                                  'Jharkhand':86.41998572,\n                                  'DVC':88.3527,\n                                  'Odisha':85.90001746,\n                                  'West Bengal':88.32994665,\n                                  'Sikkim':88.6166475,\n                                  'Arunachal Pradesh':93.61660071,\n                                  'Assam':94.21666744,\n                                  'Manipur':93.95001705,\n                                  'Meghalaya':91.8800142,\n                                  'Mizoram':92.72001461,\n                                  'Nagaland':94.11657019,\n                                  'Tripura':91.27999914\n})\ndf.dropna(thresh=2, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"s_BxZdP_OagB","trusted":true},"cell_type":"code","source":"## ADDING VALUES OF REGIONS WHICH WERE NOT EXTRACTED FROM THE PDF\ndf['Region'][0:11] = 'NR'\ndf['Region'][11:20] = 'WR'\ndf['Region'][20:27] = 'SR'\ndf['Region'][27:34] = 'ER'\ndf['Region'][34:42] = 'NER'","execution_count":null,"outputs":[]},{"metadata":{"id":"I8mlSU6kRmQz","outputId":"92ffd5f6-d9e0-43f3-864b-b1f197e4109d","executionInfo":{"status":"ok","timestamp":1591280989540,"user_tz":-330,"elapsed":1204,"user":{"displayName":"Navin Mundhra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgniN_mTRS-2UfcIm1spNh0X1ccg_lMD19cKy8PTg=s64","userId":"04409829077952489554"}},"trusted":true},"cell_type":"code","source":"## CLEANING AND CREATING COLUMNS AS MANY CONCATINATED IN ONE ROW\ndf['Requirement/Day'] = df['Requirement/day'].apply(lambda x: x.split(\" \")[0])\ndf['Energy_Met/Day'] = df['Requirement/day'].apply(lambda x: x.split(\" \")[1])\ndf.drop('Requirement/day', axis=1, inplace=True)\n\ndf['Requirement/Month'] = df['Requirement/month'].apply(lambda x: x.split(\" \")[0])\ndf['Energy_Met/Month'] = df['Requirement/month'].apply(lambda x: x.split(\" \")[1])\ndf.drop('Requirement/month', axis=1, inplace=True)\n\ndf['Peak_Demand_Requirement'] = df['peak_demand'].apply(lambda x: x.split(\" \")[0])\ndf['Peak_Demand_Met'] = df['peak_demand'].apply(lambda x: x.split(\" \")[1])\ndf.drop('peak_demand', axis=1, inplace=True)\n\ndf","execution_count":null,"outputs":[]},{"metadata":{"id":"FObBdTwnmS2x","trusted":true},"cell_type":"code","source":"## TRANSFORMING INTO A LONG FORM FOR BETTER USE IN VISUALITIONS\ndf.melt(id_vars=['Region', 'State', 'Latitude', 'Longitude'], var_name= 'Dates', value_name='Usage')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Thats about it! Thats how one can easily extract, manipulate and create data using Tabula and Pandas in Python. Do tell me in the comments if you have another alternate awesome ways! See ya :)"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}